{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoPytorch 써보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoPyTorch import AutoNetClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 DL을 하는 만큼 차원이 많은 걸 활용해보면 좋을 것 같아서 예전 TTG 경연 화학식 데이터를 써봤습니다. (용량은 17mb정도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TTG_ecfp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ecfp_0</th>\n",
       "      <th>ecfp_1</th>\n",
       "      <th>ecfp_2</th>\n",
       "      <th>ecfp_3</th>\n",
       "      <th>ecfp_4</th>\n",
       "      <th>ecfp_5</th>\n",
       "      <th>ecfp_6</th>\n",
       "      <th>ecfp_7</th>\n",
       "      <th>ecfp_8</th>\n",
       "      <th>...</th>\n",
       "      <th>ecfp_1019</th>\n",
       "      <th>ecfp_1020</th>\n",
       "      <th>ecfp_1021</th>\n",
       "      <th>ecfp_1022</th>\n",
       "      <th>ecfp_1023</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>clogp</th>\n",
       "      <th>sa_score</th>\n",
       "      <th>qed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.117</td>\n",
       "      <td>0.66380</td>\n",
       "      <td>1.951060</td>\n",
       "      <td>0.512651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.115</td>\n",
       "      <td>0.41632</td>\n",
       "      <td>2.373113</td>\n",
       "      <td>0.572518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139.176</td>\n",
       "      <td>-0.77700</td>\n",
       "      <td>2.336083</td>\n",
       "      <td>0.502646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.121</td>\n",
       "      <td>1.45910</td>\n",
       "      <td>2.624244</td>\n",
       "      <td>0.647854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162.236</td>\n",
       "      <td>1.84830</td>\n",
       "      <td>2.499926</td>\n",
       "      <td>0.626152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>8344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630.518</td>\n",
       "      <td>1.72960</td>\n",
       "      <td>4.075168</td>\n",
       "      <td>0.417863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>8345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>664.811</td>\n",
       "      <td>3.57420</td>\n",
       "      <td>4.216803</td>\n",
       "      <td>0.305624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <td>8346</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771.996</td>\n",
       "      <td>6.93428</td>\n",
       "      <td>5.419006</td>\n",
       "      <td>0.223052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>8347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>856.911</td>\n",
       "      <td>4.44280</td>\n",
       "      <td>4.286743</td>\n",
       "      <td>0.138073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>8348</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1242.488</td>\n",
       "      <td>-4.04893</td>\n",
       "      <td>7.041127</td>\n",
       "      <td>0.030538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8349 rows × 1030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ecfp_0  ecfp_1  ecfp_2  ecfp_3  ecfp_4  ecfp_5  ecfp_6  \\\n",
       "0              0       0       0       0       0       0       0       0   \n",
       "1              1       0       0       0       0       0       0       0   \n",
       "2              2       0       0       0       0       0       0       0   \n",
       "3              3       0       0       0       0       0       0       0   \n",
       "4              4       0       0       0       0       1       0       0   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "8344        8344       0       0       0       1       0       0       0   \n",
       "8345        8345       0       0       0       0       0       0       0   \n",
       "8346        8346       0       1       0       0       0       0       0   \n",
       "8347        8347       0       1       0       0       1       0       0   \n",
       "8348        8348       0       1       0       0       0       0       0   \n",
       "\n",
       "      ecfp_7  ecfp_8  ...  ecfp_1019  ecfp_1020  ecfp_1021  ecfp_1022  \\\n",
       "0          0       0  ...          0          0          0          0   \n",
       "1          0       0  ...          0          0          0          0   \n",
       "2          0       0  ...          0          0          0          0   \n",
       "3          0       0  ...          0          0          0          0   \n",
       "4          0       0  ...          1          0          0          0   \n",
       "...      ...     ...  ...        ...        ...        ...        ...   \n",
       "8344       0       0  ...          1          1          0          0   \n",
       "8345       0       0  ...          1          0          0          0   \n",
       "8346       0       0  ...          1          0          0          0   \n",
       "8347       0       0  ...          1          0          0          0   \n",
       "8348       0       0  ...          1          0          0          0   \n",
       "\n",
       "      ecfp_1023     MolWt    clogp  sa_score       qed  label  \n",
       "0             0    94.117  0.66380  1.951060  0.512651      1  \n",
       "1             0   126.115  0.41632  2.373113  0.572518      1  \n",
       "2             0   139.176 -0.77700  2.336083  0.502646      1  \n",
       "3             0   151.121  1.45910  2.624244  0.647854      1  \n",
       "4             0   162.236  1.84830  2.499926  0.626152      1  \n",
       "...         ...       ...      ...       ...       ...    ...  \n",
       "8344          0   630.518  1.72960  4.075168  0.417863      1  \n",
       "8345          0   664.811  3.57420  4.216803  0.305624      1  \n",
       "8346          0   771.996  6.93428  5.419006  0.223052      1  \n",
       "8347          0   856.911  4.44280  4.286743  0.138073      1  \n",
       "8348          0  1242.488 -4.04893  7.041127  0.030538      1  \n",
       "\n",
       "[8349 rows x 1030 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:1029]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, 1029]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그냥 제일 작은 searchspace로 구동했을 때 0.7 accuracy 도출되었음.\n",
    "\n",
    "Accu.tuning으로 했을 때는 0.79 정도 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:15 WORKER: start listening for jobs\n",
      "11:57:15 [AutoNet] Start bohb\n",
      "11:57:15 DISPATCHER: started the 'discover_worker' thread\n",
      "11:57:15 DISPATCHER: started the 'job_runner' thread\n",
      "11:57:15 DISPATCHER: Pyro daemon running on 172.30.1.34:50802\n",
      "11:57:15 DISPATCHER: discovered new worker, hpbandster.run_0.worker.Sehyeongui-MacBookPro.local.83741.-14501134784\n",
      "11:57:15 HBMASTER: adjusted queue size to (0, 1)\n",
      "11:57:15 DISPATCHER: A new worker triggered discover_worker\n",
      "11:57:15 HBMASTER: starting run at 1611197835.3274062\n",
      "11:57:15 WORKER: start processing job (0, 0, 0)\n",
      "11:57:15 Fit optimization pipeline\n",
      "11:57:15 [AutoNet] CV split 0 of 1\n",
      "11:57:15 Reduced initial budget 29.821474075317383 to cv budget 29.816375017166138 compensate for 0.005099058151245117\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "11:57:35 Finished train with budget 29.816375017166138: Preprocessing took 2s, Training took 17s, Wrap up took 0s. Total time consumption in s: 20\n",
      "11:57:35 [AutoNet] Done with current split!\n",
      "11:57:35 Aggregate the results across the splits\n",
      "11:57:35 Process 1 additional result(s)\n",
      "11:57:35 Training ['shapedresnet'] with budget 30.0 resulted in optimize-metric-loss: -69.9001996007984 took 20.585726976394653 seconds\n",
      "11:57:35 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "11:57:35 WORKER: start processing job (0, 0, 1)\n",
      "11:57:35 Fit optimization pipeline\n",
      "11:57:36 [AutoNet] CV split 0 of 1\n",
      "11:57:36 Reduced initial budget 29.81547713279724 to cv budget 29.799860954284668 compensate for 0.015616178512573242\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "11:57:56 Finished train with budget 29.799860954284668: Preprocessing took 1s, Training took 18s, Wrap up took 0s. Total time consumption in s: 20\n",
      "11:57:56 [AutoNet] Done with current split!\n",
      "11:57:56 Aggregate the results across the splits\n",
      "11:57:56 Process 1 additional result(s)\n",
      "11:57:56 Training ['shapedresnet'] with budget 30.0 resulted in optimize-metric-loss: -66.02794411177645 took 20.931497812271118 seconds\n",
      "11:57:56 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "11:57:56 WORKER: start processing job (0, 0, 2)\n",
      "11:57:56 Fit optimization pipeline\n",
      "11:57:57 [AutoNet] CV split 0 of 1\n",
      "11:57:57 Reduced initial budget 29.81067967414856 to cv budget 29.807467937469482 compensate for 0.0032117366790771484\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "11:58:17 Finished train with budget 29.807467937469482: Preprocessing took 1s, Training took 17s, Wrap up took 0s. Total time consumption in s: 20\n",
      "11:58:17 [AutoNet] Done with current split!\n",
      "11:58:17 Aggregate the results across the splits\n",
      "11:58:17 Process 1 additional result(s)\n",
      "11:58:17 Training ['shapedresnet'] with budget 30.0 resulted in optimize-metric-loss: -64.2315369261477 took 20.526796102523804 seconds\n",
      "11:58:17 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "11:58:17 WORKER: start processing job (0, 0, 0)\n",
      "11:58:17 Fit optimization pipeline\n",
      "11:58:17 [AutoNet] CV split 0 of 1\n",
      "11:58:17 Reduced initial budget 89.82225298881531 to cv budget 89.81930422782898 compensate for 0.002948760986328125\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "11:59:39 Finished train with budget 89.81930422782898: Preprocessing took 2s, Training took 79s, Wrap up took 0s. Total time consumption in s: 82\n",
      "11:59:39 [AutoNet] Done with current split!\n",
      "11:59:39 Aggregate the results across the splits\n",
      "11:59:39 Process 1 additional result(s)\n",
      "11:59:39 Training ['shapedresnet'] with budget 90.0 resulted in optimize-metric-loss: -63.952095808383234 took 82.50902795791626 seconds\n",
      "11:59:39 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "11:59:39 WORKER: start processing job (1, 0, 0)\n",
      "11:59:39 Fit optimization pipeline\n",
      "11:59:40 [AutoNet] CV split 0 of 1\n",
      "11:59:40 Reduced initial budget 89.81834197044373 to cv budget 89.81535696983337 compensate for 0.0029850006103515625\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "12:01:02 Finished train with budget 89.81535696983337: Preprocessing took 1s, Training took 78s, Wrap up took 2s. Total time consumption in s: 81\n",
      "12:01:02 [AutoNet] Done with current split!\n",
      "12:01:02 Aggregate the results across the splits\n",
      "12:01:02 Process 1 additional result(s)\n",
      "12:01:02 Training ['shapedresnet'] with budget 90.0 resulted in optimize-metric-loss: -61.197604790419156 took 82.28372812271118 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:02 WORKER: registered result for job (1, 0, 0) with dispatcher\n",
      "12:01:02 HBMASTER: Timelimit reached: wait for remaining 0 jobs\n",
      "12:01:02 DISPATCHER: Dispatcher shutting down\n",
      "12:01:02 DISPATCHER: shut down complete\n",
      "12:01:02 Start autonet with config:\n",
      "{'embeddings': ['none'], 'lr_scheduler': ['cosine_annealing'], 'networks': ['shapedresnet'], 'preprocessors': ['truncated_svd'], 'target_size_strategies': ['none'], 'over_sampling_methods': ['none'], 'under_sampling_methods': ['none'], 'batch_loss_computation_techniques': ['standard'], 'imputation_strategies': ['median'], 'initialization_methods': ['default'], 'loss_modules': ['cross_entropy_weighted'], 'normalization_strategies': ['standardize'], 'optimizer': ['sgd'], 'hyperparameter_search_space_updates': <autoPyTorch.utils.hyperparameter_search_space_update.HyperparameterSearchSpaceUpdates object at 0x7f8a05c46f90>, 'log_level': 'info', 'max_runtime': 300, 'min_budget': 30, 'max_budget': 90, 'validation_split': 0.3, 'result_logger_dir': '.', 'categorical_features': None, 'dataset_name': None, 'run_id': '0', 'task_id': -1, 'algorithm': 'bohb', 'portfolio_type': 'greedy', 'budget_type': 'time', 'eta': 3, 'min_workers': 1, 'working_dir': '.', 'network_interface_name': 'en0', 'memory_limit_mb': 1000000, 'use_tensorboard_logger': False, 'run_worker_on_master_node': True, 'use_pynisher': True, 'refit_validation_split': 0.0, 'cross_validator': 'none', 'cross_validator_args': {}, 'min_budget_for_cv': 0, 'shuffle': True, 'final_activation': 'softmax', 'initializer': 'simple_initializer', 'additional_logs': [], 'optimize_metric': 'accuracy', 'additional_metrics': [], 'cuda': True, 'torch_num_threads': 1, 'full_eval_each_epoch': False, 'best_over_epochs': False, 'save_models': False, 'predict_model': None, 'early_stopping_patience': inf, 'early_stopping_reset_parameters': False, 'random_seed': 3173622877, 'num_iterations': inf, 'cv_splits': 1, 'increase_number_of_trained_datasets': False}\n",
      "12:01:02 Start Refitting\n",
      "12:01:02 [AutoNet] CV split 0 of 1\n",
      "12:01:02 Reduced initial budget 29.95567488670349 to cv budget 29.954890966415405 compensate for 0.0007839202880859375\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "12:01:22 Finished train with budget 29.954890966415405: Preprocessing took 2s, Training took 17s, Wrap up took 0s. Total time consumption in s: 20\n",
      "12:01:23 [AutoNet] Done with current split!\n",
      "12:01:23 Aggregate the results across the splits\n",
      "12:01:23 Process 1 additional result(s)\n",
      "12:01:23 Done Refitting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optimized_hyperparameter_config': {'CreateDataLoader:batch_size': 125,\n",
       "  'Imputation:strategy': 'median',\n",
       "  'InitializationSelector:initialization_method': 'default',\n",
       "  'InitializationSelector:initializer:initialize_bias': 'No',\n",
       "  'LearningrateSchedulerSelector:lr_scheduler': 'cosine_annealing',\n",
       "  'LossModuleSelector:loss_module': 'cross_entropy_weighted',\n",
       "  'NetworkSelector:network': 'shapedresnet',\n",
       "  'NormalizationStrategySelector:normalization_strategy': 'standardize',\n",
       "  'OptimizerSelector:optimizer': 'sgd',\n",
       "  'PreprocessorSelector:preprocessor': 'truncated_svd',\n",
       "  'ResamplingStrategySelector:over_sampling_method': 'none',\n",
       "  'ResamplingStrategySelector:target_size_strategy': 'none',\n",
       "  'ResamplingStrategySelector:under_sampling_method': 'none',\n",
       "  'TrainNode:batch_loss_computation_technique': 'standard',\n",
       "  'LearningrateSchedulerSelector:cosine_annealing:T_max': 10,\n",
       "  'LearningrateSchedulerSelector:cosine_annealing:eta_min': 2,\n",
       "  'NetworkSelector:shapedresnet:activation': 'relu',\n",
       "  'NetworkSelector:shapedresnet:blocks_per_group': 4,\n",
       "  'NetworkSelector:shapedresnet:max_units': 717,\n",
       "  'NetworkSelector:shapedresnet:num_groups': 1,\n",
       "  'NetworkSelector:shapedresnet:resnet_shape': 'brick',\n",
       "  'NetworkSelector:shapedresnet:use_dropout': 0,\n",
       "  'NetworkSelector:shapedresnet:use_shake_drop': 0,\n",
       "  'NetworkSelector:shapedresnet:use_shake_shake': 0,\n",
       "  'OptimizerSelector:sgd:learning_rate': 0.008116909369177708,\n",
       "  'OptimizerSelector:sgd:momentum': 0.24464718877551866,\n",
       "  'OptimizerSelector:sgd:weight_decay': 0.08911422557941567,\n",
       "  'PreprocessorSelector:truncated_svd:target_dim': 100},\n",
       " 'budget': 30.0,\n",
       " 'loss': -69.9001996007984,\n",
       " 'info': {'loss': 0.6202219426631927,\n",
       "  'model_parameters': 4205207.0,\n",
       "  'train_accuracy': 67.54,\n",
       "  'lr_scheduler_converged': 0.0,\n",
       "  'lr': 0.329489180178242,\n",
       "  'val_accuracy': 69.9001996007984}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch = AutoNetClassification(\"tiny_cs\",  # config preset\n",
    "                                    log_level='info',\n",
    "                                    max_runtime=300,\n",
    "                                    min_budget=30,\n",
    "                                    max_budget=90)\n",
    "\n",
    "autoPyTorch.fit(X, y, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선택된 hyperparameters 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': ['none'],\n",
       " 'lr_scheduler': ['cosine_annealing'],\n",
       " 'networks': ['shapedresnet'],\n",
       " 'preprocessors': ['truncated_svd'],\n",
       " 'target_size_strategies': ['none'],\n",
       " 'over_sampling_methods': ['none'],\n",
       " 'under_sampling_methods': ['none'],\n",
       " 'batch_loss_computation_techniques': ['standard'],\n",
       " 'imputation_strategies': ['median'],\n",
       " 'initialization_methods': ['default'],\n",
       " 'loss_modules': ['cross_entropy_weighted'],\n",
       " 'normalization_strategies': ['standardize'],\n",
       " 'optimizer': ['sgd'],\n",
       " 'hyperparameter_search_space_updates': <autoPyTorch.utils.hyperparameter_search_space_update.HyperparameterSearchSpaceUpdates at 0x7f8a24043b10>,\n",
       " 'log_level': 'info',\n",
       " 'max_runtime': 300,\n",
       " 'min_budget': 30,\n",
       " 'max_budget': 90,\n",
       " 'validation_split': 0.3,\n",
       " 'result_logger_dir': '.',\n",
       " 'categorical_features': None,\n",
       " 'dataset_name': None,\n",
       " 'run_id': '0',\n",
       " 'task_id': -1,\n",
       " 'algorithm': 'bohb',\n",
       " 'portfolio_type': 'greedy',\n",
       " 'budget_type': 'time',\n",
       " 'eta': 3,\n",
       " 'min_workers': 1,\n",
       " 'working_dir': '.',\n",
       " 'network_interface_name': 'en0',\n",
       " 'memory_limit_mb': 1000000,\n",
       " 'use_tensorboard_logger': False,\n",
       " 'run_worker_on_master_node': True,\n",
       " 'use_pynisher': True,\n",
       " 'refit_validation_split': 0.0,\n",
       " 'cross_validator': 'none',\n",
       " 'cross_validator_args': {},\n",
       " 'min_budget_for_cv': 0,\n",
       " 'shuffle': True,\n",
       " 'final_activation': 'softmax',\n",
       " 'initializer': 'simple_initializer',\n",
       " 'additional_logs': [],\n",
       " 'optimize_metric': 'accuracy',\n",
       " 'additional_metrics': [],\n",
       " 'cuda': False,\n",
       " 'torch_num_threads': 1,\n",
       " 'full_eval_each_epoch': False,\n",
       " 'best_over_epochs': False,\n",
       " 'save_models': False,\n",
       " 'predict_model': None,\n",
       " 'early_stopping_patience': inf,\n",
       " 'early_stopping_reset_parameters': False,\n",
       " 'random_seed': 3173622877,\n",
       " 'num_iterations': inf}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch.get_current_autonet_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter searchspace 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    CreateDataLoader:batch_size, Type: Constant, Value: 125\n",
       "    Imputation:strategy, Type: Categorical, Choices: {median}, Default: median\n",
       "    InitializationSelector:initialization_method, Type: Categorical, Choices: {default}, Default: default\n",
       "    InitializationSelector:initializer:initialize_bias, Type: Constant, Value: No\n",
       "    LearningrateSchedulerSelector:cosine_annealing:T_max, Type: Constant, Value: 10\n",
       "    LearningrateSchedulerSelector:cosine_annealing:eta_min, Type: Constant, Value: 2\n",
       "    LearningrateSchedulerSelector:lr_scheduler, Type: Categorical, Choices: {cosine_annealing}, Default: cosine_annealing\n",
       "    LossModuleSelector:loss_module, Type: Categorical, Choices: {cross_entropy_weighted}, Default: cross_entropy_weighted\n",
       "    NetworkSelector:network, Type: Categorical, Choices: {shapedresnet}, Default: shapedresnet\n",
       "    NetworkSelector:shapedresnet:activation, Type: Constant, Value: relu\n",
       "    NetworkSelector:shapedresnet:blocks_per_group, Type: UniformInteger, Range: [1, 4], Default: 2\n",
       "    NetworkSelector:shapedresnet:max_units, Type: UniformInteger, Range: [10, 1024], Default: 101, on log-scale\n",
       "    NetworkSelector:shapedresnet:num_groups, Type: UniformInteger, Range: [1, 9], Default: 5\n",
       "    NetworkSelector:shapedresnet:resnet_shape, Type: Constant, Value: brick\n",
       "    NetworkSelector:shapedresnet:use_dropout, Type: Constant, Value: 0\n",
       "    NetworkSelector:shapedresnet:use_shake_drop, Type: Constant, Value: 0\n",
       "    NetworkSelector:shapedresnet:use_shake_shake, Type: Constant, Value: 0\n",
       "    NormalizationStrategySelector:normalization_strategy, Type: Categorical, Choices: {standardize}, Default: standardize\n",
       "    OptimizerSelector:optimizer, Type: Categorical, Choices: {sgd}, Default: sgd\n",
       "    OptimizerSelector:sgd:learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
       "    OptimizerSelector:sgd:momentum, Type: UniformFloat, Range: [0.1, 0.999], Default: 0.5495\n",
       "    OptimizerSelector:sgd:weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005\n",
       "    PreprocessorSelector:preprocessor, Type: Categorical, Choices: {truncated_svd}, Default: truncated_svd\n",
       "    PreprocessorSelector:truncated_svd:target_dim, Type: Constant, Value: 100\n",
       "    ResamplingStrategySelector:over_sampling_method, Type: Categorical, Choices: {none}, Default: none\n",
       "    ResamplingStrategySelector:target_size_strategy, Type: Categorical, Choices: {none}, Default: none\n",
       "    ResamplingStrategySelector:under_sampling_method, Type: Categorical, Choices: {none}, Default: none\n",
       "    TrainNode:batch_loss_computation_technique, Type: Categorical, Choices: {standard}, Default: standard\n",
       "  Conditions:\n",
       "    LearningrateSchedulerSelector:cosine_annealing:T_max | LearningrateSchedulerSelector:lr_scheduler == 'cosine_annealing'\n",
       "    LearningrateSchedulerSelector:cosine_annealing:eta_min | LearningrateSchedulerSelector:lr_scheduler == 'cosine_annealing'\n",
       "    NetworkSelector:shapedresnet:activation | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:blocks_per_group | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:max_units | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:num_groups | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:resnet_shape | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:use_dropout | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:use_shake_drop | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:use_shake_shake | NetworkSelector:network == 'shapedresnet'\n",
       "    OptimizerSelector:sgd:learning_rate | OptimizerSelector:optimizer == 'sgd'\n",
       "    OptimizerSelector:sgd:momentum | OptimizerSelector:optimizer == 'sgd'\n",
       "    OptimizerSelector:sgd:weight_decay | OptimizerSelector:optimizer == 'sgd'\n",
       "    PreprocessorSelector:truncated_svd:target_dim | PreprocessorSelector:preprocessor == 'truncated_svd'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch.get_hyperparameter_search_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch.predict(X.iloc[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch.score(X.iloc[:100,:], y[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 구조 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=717, bias=True)\n",
       "  (1): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=717, out_features=717, bias=True)\n",
       "        (3): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=717, out_features=717, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=717, out_features=717, bias=True)\n",
       "        (3): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=717, out_features=717, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=717, out_features=717, bias=True)\n",
       "        (3): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=717, out_features=717, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=717, out_features=717, bias=True)\n",
       "        (3): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=717, out_features=717, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): BatchNorm1d(717, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=717, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch.get_pytorch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래처럼 pytorch model 저장 가능. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(autoPyTorch, 'a.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiny_cs 말고 config preset을 medium으로 설정하고 돌리니 시간 초과로 로컬에서 돌아가지가 않았음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:20:19 Start autonet with config:\n",
      "{'embeddings': ['none'], 'lr_scheduler': ['cosine_annealing', 'plateau'], 'networks': ['shapedresnet'], 'over_sampling_methods': ['smote'], 'preprocessors': ['none', 'truncated_svd', 'power_transformer'], 'target_size_strategies': ['none', 'upsample', 'median'], 'log_level': 'info', 'max_runtime': 3000, 'min_budget': 300, 'max_budget': 600, 'validation_split': 0.3, 'hyperparameter_search_space_updates': None, 'result_logger_dir': '.', 'categorical_features': None, 'dataset_name': None, 'run_id': '0', 'task_id': -1, 'algorithm': 'bohb', 'portfolio_type': 'greedy', 'budget_type': 'time', 'eta': 3, 'min_workers': 1, 'working_dir': '.', 'network_interface_name': 'en0', 'memory_limit_mb': 1000000, 'use_tensorboard_logger': False, 'run_worker_on_master_node': True, 'use_pynisher': True, 'refit_validation_split': 0.0, 'cross_validator': 'none', 'cross_validator_args': {}, 'min_budget_for_cv': 0, 'shuffle': True, 'imputation_strategies': ['mean', 'median', 'most_frequent'], 'normalization_strategies': ['none', 'minmax', 'standardize', 'maxabs'], 'under_sampling_methods': ['none', 'random'], 'final_activation': 'softmax', 'initialization_methods': ['default', 'sparse'], 'initializer': 'simple_initializer', 'optimizer': ['adam', 'adamw', 'sgd', 'rmsprop'], 'additional_logs': [], 'optimize_metric': 'accuracy', 'additional_metrics': [], 'loss_modules': ['cross_entropy', 'cross_entropy_weighted'], 'batch_loss_computation_techniques': ['standard', 'mixup'], 'cuda': True, 'torch_num_threads': 1, 'full_eval_each_epoch': False, 'best_over_epochs': False, 'save_models': False, 'predict_model': None, 'early_stopping_patience': inf, 'early_stopping_reset_parameters': False, 'random_seed': 3173622877, 'num_iterations': inf}\n",
      "16:20:19 WORKER: start listening for jobs\n",
      "16:20:19 [AutoNet] Start bohb\n",
      "16:20:19 DISPATCHER: started the 'discover_worker' thread\n",
      "16:20:19 DISPATCHER: started the 'job_runner' thread\n",
      "16:20:19 DISPATCHER: Pyro daemon running on 172.30.1.34:56443\n",
      "16:20:19 DISPATCHER: discovered new worker, hpbandster.run_0.worker.Sehyeongui-MacBookPro.local.83741.-14501134784\n",
      "16:20:19 HBMASTER: adjusted queue size to (0, 1)\n",
      "16:20:19 DISPATCHER: A new worker triggered discover_worker\n",
      "16:20:19 HBMASTER: starting run at 1611213619.9161658\n",
      "16:20:19 WORKER: start processing job (0, 0, 0)\n",
      "16:20:19 Fit optimization pipeline\n",
      "16:20:20 [AutoNet] CV split 0 of 1\n",
      "16:20:20 Reduced initial budget 599.7600231170654 to cv budget 599.7542419433594 compensate for 0.0057811737060546875\n",
      "16:34:20 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "16:34:20 job (0, 0, 0) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/worker.py\", line 81, in compute\n",
      "    raise Exception(\"Time limit reached. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\n",
      "Exception: Time limit reached. Took 840.0839958190918 seconds with budget 600.0\n",
      "\n",
      "16:34:20 WORKER: start processing job (1, 0, 0)\n",
      "16:34:20 Fit optimization pipeline\n",
      "16:34:20 [AutoNet] CV split 0 of 1\n",
      "16:34:20 Reduced initial budget 599.7140998840332 to cv budget 599.71133685112 compensate for 0.002763032913208008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:48:20 WORKER: registered result for job (1, 0, 0) with dispatcher\n",
      "16:48:20 job (1, 0, 0) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/worker.py\", line 81, in compute\n",
      "    raise Exception(\"Time limit reached. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\n",
      "Exception: Time limit reached. Took 840.0586531162262 seconds with budget 600.0\n",
      "\n",
      "16:48:20 WORKER: start processing job (2, 0, 0)\n",
      "16:48:20 Fit optimization pipeline\n",
      "16:48:20 [AutoNet] CV split 0 of 1\n",
      "16:48:20 Reduced initial budget 599.8360922336578 to cv budget 599.8329582214355 compensate for 0.003134012222290039\n",
      "17:02:20 WORKER: registered result for job (2, 0, 0) with dispatcher\n",
      "17:02:20 job (2, 0, 0) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/worker.py\", line 81, in compute\n",
      "    raise Exception(\"Time limit reached. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\n",
      "Exception: Time limit reached. Took 840.0592639446259 seconds with budget 600.0\n",
      "\n",
      "17:02:20 HBMASTER: Timelimit reached: wait for remaining 0 jobs\n",
      "17:02:20 DISPATCHER: Dispatcher shutting down\n",
      "17:02:20 DISPATCHER: shut down complete\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/pipeline/nodes/optimization_algorithm.py\", line 315, in parse_results\n",
      "    incumbent_trajectory = res.get_incumbent_trajectory(bigger_is_better=False, non_decreasing_budget=False)\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/hpbandster/core/result.py\", line 310, in get_incumbent_trajectory\n",
      "    return_dict['config_ids'].append(return_dict['config_ids'][-1])\n",
      "IndexError: list index out of range\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/pipeline/nodes/optimization_algorithm.py\", line 133, in fit\n",
      "    res = self.parse_results(pipeline_config)\n",
      "  File \"/Users/sehyeongkim/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/pipeline/nodes/optimization_algorithm.py\", line 317, in parse_results\n",
      "    raise RuntimeError(\"Error parsing results. Check results.json and output for more details. An empty results.json is usually caused by a misconfiguration of AutoNet.\")\n",
      "RuntimeError: Error parsing results. Check results.json and output for more details. An empty results.json is usually caused by a misconfiguration of AutoNet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing results. Check results.json and output for more details. An empty results.json is usually caused by a misconfiguration of AutoNet.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models fit during training, please retry with a larger max_runtime.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-35b0d16fcf62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                      max_budget=600)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mautoPyTorch_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/autoPytorch/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg/autoPyTorch/core/api.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, X_valid, Y_valid, refit, **autonet_config)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"optimized_hyperparameter_config\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimized_hyperparameter_config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# MODIFY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No models fit during training, please retry with a larger max_runtime.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No models fit during training, please retry with a larger max_runtime."
     ]
    }
   ],
   "source": [
    "autoPyTorch_2 = AutoNetClassification(\"medium_cs\",  # config preset\n",
    "                                    log_level='info',\n",
    "                                     max_runtime=3000,\n",
    "                                     min_budget=300,\n",
    "                                     max_budget=600)\n",
    "\n",
    "autoPyTorch_2.fit(X, y, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': ['none'],\n",
       " 'lr_scheduler': ['cosine_annealing', 'plateau'],\n",
       " 'networks': ['shapedresnet'],\n",
       " 'over_sampling_methods': ['smote'],\n",
       " 'preprocessors': ['none', 'truncated_svd', 'power_transformer'],\n",
       " 'target_size_strategies': ['none', 'upsample', 'median'],\n",
       " 'log_level': 'info',\n",
       " 'max_runtime': 3000,\n",
       " 'min_budget': 300,\n",
       " 'max_budget': 600,\n",
       " 'validation_split': 0.3,\n",
       " 'hyperparameter_search_space_updates': None,\n",
       " 'result_logger_dir': '.',\n",
       " 'categorical_features': None,\n",
       " 'dataset_name': None,\n",
       " 'run_id': '0',\n",
       " 'task_id': -1,\n",
       " 'algorithm': 'bohb',\n",
       " 'portfolio_type': 'greedy',\n",
       " 'budget_type': 'time',\n",
       " 'eta': 3,\n",
       " 'min_workers': 1,\n",
       " 'working_dir': '.',\n",
       " 'network_interface_name': 'en0',\n",
       " 'memory_limit_mb': 1000000,\n",
       " 'use_tensorboard_logger': False,\n",
       " 'run_worker_on_master_node': True,\n",
       " 'use_pynisher': True,\n",
       " 'refit_validation_split': 0.0,\n",
       " 'cross_validator': 'none',\n",
       " 'cross_validator_args': {},\n",
       " 'min_budget_for_cv': 0,\n",
       " 'shuffle': True,\n",
       " 'imputation_strategies': ['mean', 'median', 'most_frequent'],\n",
       " 'normalization_strategies': ['none', 'minmax', 'standardize', 'maxabs'],\n",
       " 'under_sampling_methods': ['none', 'random'],\n",
       " 'final_activation': 'softmax',\n",
       " 'initialization_methods': ['default', 'sparse'],\n",
       " 'initializer': 'simple_initializer',\n",
       " 'optimizer': ['adam', 'adamw', 'sgd', 'rmsprop'],\n",
       " 'additional_logs': [],\n",
       " 'optimize_metric': 'accuracy',\n",
       " 'additional_metrics': [],\n",
       " 'loss_modules': ['cross_entropy', 'cross_entropy_weighted'],\n",
       " 'batch_loss_computation_techniques': ['standard', 'mixup'],\n",
       " 'cuda': True,\n",
       " 'torch_num_threads': 1,\n",
       " 'full_eval_each_epoch': False,\n",
       " 'best_over_epochs': False,\n",
       " 'save_models': False,\n",
       " 'predict_model': None,\n",
       " 'early_stopping_patience': inf,\n",
       " 'early_stopping_reset_parameters': False,\n",
       " 'random_seed': 3173622877,\n",
       " 'num_iterations': inf}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch_2.get_current_autonet_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    CreateDataLoader:batch_size, Type: UniformInteger, Range: [32, 500], Default: 126, on log-scale\n",
       "    Imputation:strategy, Type: Categorical, Choices: {mean, median, most_frequent}, Default: mean\n",
       "    InitializationSelector:initialization_method, Type: Categorical, Choices: {default, sparse}, Default: default\n",
       "    InitializationSelector:initializer:initialize_bias, Type: Categorical, Choices: {Yes, No, Zero}, Default: Yes\n",
       "    InitializationSelector:sparse:sparsity, Type: Constant, Value: 0.9\n",
       "    LearningrateSchedulerSelector:cosine_annealing:T_max, Type: UniformInteger, Range: [10, 500], Default: 255\n",
       "    LearningrateSchedulerSelector:cosine_annealing:eta_min, Type: Constant, Value: 1e-08\n",
       "    LearningrateSchedulerSelector:lr_scheduler, Type: Categorical, Choices: {cosine_annealing, plateau}, Default: cosine_annealing\n",
       "    LearningrateSchedulerSelector:plateau:factor, Type: UniformFloat, Range: [0.05, 0.5], Default: 0.275\n",
       "    LearningrateSchedulerSelector:plateau:patience, Type: UniformInteger, Range: [3, 10], Default: 6\n",
       "    LossModuleSelector:loss_module, Type: Categorical, Choices: {cross_entropy, cross_entropy_weighted}, Default: cross_entropy\n",
       "    NetworkSelector:network, Type: Categorical, Choices: {shapedresnet}, Default: shapedresnet\n",
       "    NetworkSelector:shapedresnet:activation, Type: Categorical, Choices: {sigmoid, tanh, relu}, Default: sigmoid\n",
       "    NetworkSelector:shapedresnet:blocks_per_group, Type: UniformInteger, Range: [1, 4], Default: 2\n",
       "    NetworkSelector:shapedresnet:max_dropout, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5\n",
       "    NetworkSelector:shapedresnet:max_shake_drop_probability, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5\n",
       "    NetworkSelector:shapedresnet:max_units, Type: UniformInteger, Range: [10, 1024], Default: 101, on log-scale\n",
       "    NetworkSelector:shapedresnet:num_groups, Type: UniformInteger, Range: [1, 9], Default: 5\n",
       "    NetworkSelector:shapedresnet:resnet_shape, Type: Categorical, Choices: {funnel, long_funnel, diamond, hexagon, brick, triangle, stairs}, Default: funnel\n",
       "    NetworkSelector:shapedresnet:use_dropout, Type: Categorical, Choices: {True, False}, Default: True\n",
       "    NetworkSelector:shapedresnet:use_shake_drop, Type: Categorical, Choices: {True, False}, Default: True\n",
       "    NetworkSelector:shapedresnet:use_shake_shake, Type: Categorical, Choices: {True, False}, Default: True\n",
       "    NormalizationStrategySelector:normalization_strategy, Type: Categorical, Choices: {maxabs, minmax, none, standardize}, Default: maxabs\n",
       "    OptimizerSelector:adam:learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
       "    OptimizerSelector:adam:weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005\n",
       "    OptimizerSelector:adamw:learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
       "    OptimizerSelector:adamw:weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005\n",
       "    OptimizerSelector:optimizer, Type: Categorical, Choices: {adam, adamw, rmsprop, sgd}, Default: adam\n",
       "    OptimizerSelector:rmsprop:alpha, Type: UniformFloat, Range: [0.1, 0.99], Default: 0.545\n",
       "    OptimizerSelector:rmsprop:learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
       "    OptimizerSelector:rmsprop:momentum, Type: UniformFloat, Range: [0.1, 0.99], Default: 0.3146426545, on log-scale\n",
       "    OptimizerSelector:rmsprop:weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005\n",
       "    OptimizerSelector:sgd:learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0031622777, on log-scale\n",
       "    OptimizerSelector:sgd:momentum, Type: UniformFloat, Range: [0.1, 0.999], Default: 0.5495\n",
       "    OptimizerSelector:sgd:weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005\n",
       "    PreprocessorSelector:power_transformer:method, Type: Categorical, Choices: {yeo-johnson, box-cox}, Default: yeo-johnson\n",
       "    PreprocessorSelector:power_transformer:standardize, Type: Categorical, Choices: {True, False}, Default: True\n",
       "    PreprocessorSelector:preprocessor, Type: Categorical, Choices: {none, power_transformer, truncated_svd}, Default: none\n",
       "    PreprocessorSelector:truncated_svd:target_dim, Type: UniformInteger, Range: [10, 256], Default: 133\n",
       "    ResamplingStrategySelector:over_sampling_method, Type: Categorical, Choices: {smote}, Default: smote\n",
       "    ResamplingStrategySelector:smote:k_neighbors, Type: UniformInteger, Range: [3, 7], Default: 5\n",
       "    ResamplingStrategySelector:target_size_strategy, Type: Categorical, Choices: {median, none, upsample}, Default: median\n",
       "    ResamplingStrategySelector:under_sampling_method, Type: Categorical, Choices: {none, random}, Default: none\n",
       "    TrainNode:batch_loss_computation_technique, Type: Categorical, Choices: {mixup, standard}, Default: mixup\n",
       "    TrainNode:mixup:alpha, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5\n",
       "  Conditions:\n",
       "    InitializationSelector:sparse:sparsity | InitializationSelector:initialization_method == 'sparse'\n",
       "    LearningrateSchedulerSelector:cosine_annealing:T_max | LearningrateSchedulerSelector:lr_scheduler == 'cosine_annealing'\n",
       "    LearningrateSchedulerSelector:cosine_annealing:eta_min | LearningrateSchedulerSelector:lr_scheduler == 'cosine_annealing'\n",
       "    LearningrateSchedulerSelector:plateau:factor | LearningrateSchedulerSelector:lr_scheduler == 'plateau'\n",
       "    LearningrateSchedulerSelector:plateau:patience | LearningrateSchedulerSelector:lr_scheduler == 'plateau'\n",
       "    NetworkSelector:shapedresnet:activation | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:blocks_per_group | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:max_dropout | NetworkSelector:shapedresnet:use_dropout == True\n",
       "    NetworkSelector:shapedresnet:max_shake_drop_probability | NetworkSelector:shapedresnet:use_shake_drop == True\n",
       "    NetworkSelector:shapedresnet:max_units | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:num_groups | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:resnet_shape | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:use_dropout | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:use_shake_drop | NetworkSelector:network == 'shapedresnet'\n",
       "    NetworkSelector:shapedresnet:use_shake_shake | NetworkSelector:network == 'shapedresnet'\n",
       "    OptimizerSelector:adam:learning_rate | OptimizerSelector:optimizer == 'adam'\n",
       "    OptimizerSelector:adam:weight_decay | OptimizerSelector:optimizer == 'adam'\n",
       "    OptimizerSelector:adamw:learning_rate | OptimizerSelector:optimizer == 'adamw'\n",
       "    OptimizerSelector:adamw:weight_decay | OptimizerSelector:optimizer == 'adamw'\n",
       "    OptimizerSelector:rmsprop:alpha | OptimizerSelector:optimizer == 'rmsprop'\n",
       "    OptimizerSelector:rmsprop:learning_rate | OptimizerSelector:optimizer == 'rmsprop'\n",
       "    OptimizerSelector:rmsprop:momentum | OptimizerSelector:optimizer == 'rmsprop'\n",
       "    OptimizerSelector:rmsprop:weight_decay | OptimizerSelector:optimizer == 'rmsprop'\n",
       "    OptimizerSelector:sgd:learning_rate | OptimizerSelector:optimizer == 'sgd'\n",
       "    OptimizerSelector:sgd:momentum | OptimizerSelector:optimizer == 'sgd'\n",
       "    OptimizerSelector:sgd:weight_decay | OptimizerSelector:optimizer == 'sgd'\n",
       "    PreprocessorSelector:power_transformer:method | PreprocessorSelector:preprocessor == 'power_transformer'\n",
       "    PreprocessorSelector:power_transformer:standardize | PreprocessorSelector:preprocessor == 'power_transformer'\n",
       "    PreprocessorSelector:truncated_svd:target_dim | PreprocessorSelector:preprocessor == 'truncated_svd'\n",
       "    ResamplingStrategySelector:smote:k_neighbors | ResamplingStrategySelector:over_sampling_method == 'smote'\n",
       "    TrainNode:mixup:alpha | TrainNode:batch_loss_computation_technique == 'mixup'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoPyTorch_2.get_hyperparameter_search_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
